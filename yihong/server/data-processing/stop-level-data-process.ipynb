{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import dirname\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "\n",
    "## from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import dump\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced lag IDs\n",
      "Converted NAs to np.nan\n"
     ]
    }
   ],
   "source": [
    "is_for_deploy = False\n",
    "\n",
    "runtime = pd.read_parquet(\"C:/Users/huyh/Documents/Penn/Spring 2023/Cloud Computing/cloud-computing-bus-bunching/server/raw-data/runtimeDf.gzip\")\n",
    "\n",
    "runtime = runtime.query(\"routeId.isin(['21', '33', '47'])\").copy()\n",
    "\n",
    "toJoinFrom = runtime.copy().dropna(subset=[\"instanceId\"])\n",
    "same_trip_cols = [\"serviceDate\", \"routeId\", \"directionId\", \"tripId\"]\n",
    "\n",
    "toJoin = toJoinFrom[[\"instanceId\", \"prevInstanceId\"]].dropna(\n",
    "    subset=[\"instanceId\", \"prevInstanceId\"]\n",
    ")\n",
    "\n",
    "runtimeDf = runtime.copy()\n",
    "\n",
    "for lagSteps in range(1, 22):\n",
    "    # First get lag trips\n",
    "    runtimeDf = runtimeDf.sort_values(same_trip_cols + [\"toStopSequence\"])\n",
    "    runtimeDf[f\"lag{lagSteps}InstanceId\"] = runtimeDf.groupby(same_trip_cols)[\n",
    "        \"instanceId\"\n",
    "    ].shift(lagSteps)\n",
    "\n",
    "    # Then get prev buses of lag trips\n",
    "    thisToJoin = toJoin.copy().rename(\n",
    "        columns={\n",
    "            \"instanceId\": f\"lag{lagSteps}InstanceId\",\n",
    "            \"prevInstanceId\": f\"lag{lagSteps}PrevInstanceId\",\n",
    "        }\n",
    "    )\n",
    "    runtimeDf = runtimeDf.merge(thisToJoin, how=\"left\", on=f\"lag{lagSteps}InstanceId\")\n",
    "\n",
    "print(\"Produced lag IDs\")\n",
    "\n",
    "runtimeDf = runtimeDf.applymap(lambda x: np.nan if x is pd.NA else x)\n",
    "\n",
    "print(\"Converted NAs to np.nan\")\n",
    "\n",
    "lag_vars = [\"headway\", \"speed\", \"late\"]\n",
    "\n",
    "for lagSteps in range(1, 22):\n",
    "    # Join to lag\n",
    "\n",
    "    thisToJoin = (\n",
    "        toJoinFrom.copy()[[\"instanceId\"] + lag_vars]\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"instanceId\": f\"lag{lagSteps}InstanceId\",\n",
    "                \"headway\": f\"headwayLag{lagSteps}\",\n",
    "                \"speed\": f\"speedLag{lagSteps}\",\n",
    "                \"late\": f\"lateLag{lagSteps}\",\n",
    "            }\n",
    "        )\n",
    "        .dropna(subset=[f\"lag{lagSteps}InstanceId\"])\n",
    "    )\n",
    "\n",
    "    runtimeDf = runtimeDf.merge(thisToJoin, how=\"left\", on=f\"lag{lagSteps}InstanceId\")\n",
    "\n",
    "    # Join to prev of lag\n",
    "\n",
    "    thisToJoin = (\n",
    "        toJoinFrom.copy()[[\"instanceId\"] + lag_vars]\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"instanceId\": f\"lag{lagSteps}PrevInstanceId\",\n",
    "                \"headway\": f\"prevBus_headwayLag{lagSteps}\",\n",
    "                \"speed\": f\"prevBus_speedLag{lagSteps}\",\n",
    "                \"late\": f\"prevBus_lateLag{lagSteps}\",\n",
    "            }\n",
    "        )\n",
    "        .dropna(subset=[f\"lag{lagSteps}PrevInstanceId\"])\n",
    "    )\n",
    "\n",
    "    runtimeDf = runtimeDf.merge(\n",
    "        thisToJoin, how=\"left\", on=f\"lag{lagSteps}PrevInstanceId\"\n",
    "    )\n",
    "\n",
    "for lagSteps in range(1, 21):\n",
    "    for var in lag_vars:\n",
    "        runtimeDf[f\"{var}Lag{lagSteps}Diff{lagSteps+1}\"] = (\n",
    "            runtimeDf[f\"{var}Lag{lagSteps}\"] - runtimeDf[f\"{var}Lag{lagSteps+1}\"]\n",
    "        )\n",
    "        runtimeDf[f\"prevBus_{var}Lag{lagSteps}Diff{lagSteps+1}\"] = (\n",
    "            runtimeDf[f\"prevBus_{var}Lag{lagSteps}\"]\n",
    "            - runtimeDf[f\"prevBus_{var}Lag{lagSteps+1}\"]\n",
    "        )\n",
    "\n",
    "# stops = gpd.read_file(f\"{server_dir}/raw-data/stops/stopsGeographyProcessed.shp\")\n",
    "# stops = stops.rename(columns={\"directionI\": \"directionId\", \"StopId\": \"stopId\"}).drop(\n",
    "#     \"geography\", axis=1\n",
    "# )\n",
    "\n",
    "# stops.routeId = stops.routeId.astype(str)\n",
    "# stops.directionId = stops.directionId.astype(str)\n",
    "# stops.stopId = stops.stopId.astype(str)\n",
    "\n",
    "# stops = stops.drop_duplicates(subset=[\"routeId\", \"directionId\", \"stopId\"])\n",
    "\n",
    "# runtimeDf = runtimeDf.merge(\n",
    "#     stops[[\"routeId\", \"directionId\", \"stopId\", \"centerCity\"]],\n",
    "#     how=\"left\",\n",
    "#     left_on=[\"routeId\", \"directionId\", \"toStopId\"],\n",
    "#     right_on=[\"routeId\", \"directionId\", \"stopId\"],\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_level = pd.read_csv(\"C:/Users/huyh/Documents/Penn/Spring 2023/Cloud Computing/cloud-computing-bus-bunching/server/raw-data/stops_spatial_lag.csv\", \n",
    "                         index_col=False)\n",
    "stop_level = stop_level.drop('toStopSequence',  axis = 1)\n",
    "stop_level.routeId = stop_level.routeId.astype(str)\n",
    "stop_level.directionId = stop_level.directionId.astype(str).apply(lambda x: x.split('.')[0])\n",
    "stop_level.toStopId = stop_level.toStopId.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf = runtimeDf.merge(stop_level, how = \"left\", on = ['routeId', 'directionId', 'toStopId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoW                     object\n",
      "serviceDate     datetime64[ns]\n",
      "routeId                 object\n",
      "directionId             object\n",
      "blockId                  int64\n",
      "                     ...      \n",
      "sumComm_15             float64\n",
      "sumComm_20             float64\n",
      "pctSignal_15           float64\n",
      "pctSignal_10           float64\n",
      "pctSignal_20           float64\n",
      "Length: 360, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(runtimeDf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_na_col = ['sumRiders_10', 'sumRiders_20', 'sumComm_10', 'sumComm_20', 'pctSignal_10', 'pctSignal_20', 'pop','popDen', 'riders', 'commuter', 'comm_count' ]\n",
    "mean = runtimeDf[fill_na_col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf[fill_na_col] = runtimeDf[fill_na_col].fillna(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf_variables = runtimeDf[['sumRiders_10', 'sumRiders_20', 'sumComm_10', 'sumComm_20', 'pctSignal_10', 'pctSignal_20', 'pop','popDen', 'riders', 'commuter', 'comm_count', 'routeId', 'toStopId', 'directionId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf_variables.to_parquet(\"server/raw-data/stop_level_var.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.read_parquet(\"C:/Users/huyh/Documents/Penn/Spring 2023/Cloud Computing/cloud-computing-bus-bunching/server/raw-data/stop_level_var.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.dtypes\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "314b137837e6e625997df058595593ddbd6f3abb69e21a1033f4892da65dbf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
